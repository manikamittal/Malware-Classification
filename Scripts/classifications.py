from config import conf
from csvToArray import featureArray
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn import linear_model
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.svm import NuSVC
from sklearn.svm import LinearSVC
from plotAccuracy import plotAccuracy
import numpy as np

trainData, trainLabel = featureArray(conf['train']['feature_vector'])
validationData, validationLabel = featureArray(conf['valid']['feature_vector'])
testData, testLabel = featureArray(conf['test']['feature_vector'])

guideToGraph = {}

def knnClassifier():
    # checking for 10 neighbors
    maximumValue = 0
    returnParameters = []
    for neighbor in xrange(1,11):
        neighAuto = KNeighborsClassifier(n_neighbors=neighbor, algorithm='auto', p=2)
        neighDistance = KNeighborsClassifier(n_neighbors=neighbor, algorithm='auto', p=2,weights='distance')
        neighAuto.fit(trainData, trainLabel)
        neighDistance.fit(trainData,trainLabel)
        scoreAuto = neighAuto.score(validationData, validationLabel)
        scoreDistance = neighDistance.score(validationData, validationLabel)
        if max(scoreAuto,scoreDistance) > maximumValue:
            maximumValue = max(scoreAuto,scoreDistance)
            returnParameters[0] = neighbor
            returnParameters[1] = 'distance' if scoreDistance>scoreAuto else 'uniform'

    # Do we fit the entire (training+validation) data here ? If yes just need to do a vertical concatenate
    # neighTest = KNeighborsClassifier(n_neighbors=returnParameters[0], algorithm='auto', p=2,weights=returnParameters[1])
    # neighTest.fit(trainData, trainLabel)
    # scoreTest = neighTest.score(testData, testLabel)
    # guideToGraph['KNN'] = scoreTest

def radiusNeighborClassifier():
    maximumValue = 0
    returnParameters = []
    for neighbor in xrange(100,1001,100):
        neighAutoRadius = RadiusNeighborsClassifier(radius=neighbor, weights='uniform',algorithm='auto', p=2,metric='minkowski')
        neighAutoRadius.fit(trainData, trainLabel)
        neighDistanceRadius = RadiusNeighborsClassifier(radius=neighbor, weights='distance',algorithm='auto', p=2,metric='minkowski')
        neighDistanceRadius.fit(trainData, trainLabel)
        scoreAuto = neighAutoRadius.score(validationData, validationLabel)
        scoreDistance = neighDistanceRadius.score(validationData, validationLabel)
        if max(scoreAuto,scoreDistance) > maximumValue:
            maximumValue = max(scoreAuto,scoreDistance)
            returnParameters[0] = neighbor
            returnParameters[1] = 'distance' if scoreDistance>scoreAuto else 'uniform'

    # neighTest = RadiusNeighborsClassifier(radius=returnParameters[0], weights=returnParameters[1],algorithm='auto', p=2,metric='minkowski')
    # neighTest.fit(trainData, trainLabel)
    # scoreTest = neighTest.score(testData, testLabel)
    # guideToGraph['Radius Neighbor'] = scoreTest


# FIX DECISION TREE
def decisionTreeClassifier():

    maxRandomPerformance = []
    for value in xrange(10):
        clf = tree.DecisionTreeClassifier(criterion='entropy')
        clf.fit(trainData, trainLabel)
        maxRandomPerformance.append(clf.score(validationData, validationLabel))

    guideToGraph['Decision (IG)'] = max(maxRandomPerformance)

    maxRandomPerformance = []
    for value in xrange(10):
        clf = tree.DecisionTreeClassifier(criterion='gini')
        clf.fit(trainData, trainLabel)
        maxRandomPerformance.append(clf.score(validationData, validationLabel))

    guideToGraph['Decision (Gini)'] = max(maxRandomPerformance)

# CHECK IF RANDOM FOREST CAN BE FIXED
def randomForestClassify():


    maxRandomPerformance = []
    for value in xrange(1,50):
        clf = RandomForestClassifier(n_estimators = value,criterion='entropy')
        clf = clf.fit(trainData,trainLabel)
        score = clf.score(validationData, validationLabel)
        maxRandomPerformance.append(score)

    guideToGraph['Random Forests'] = max(maxRandomPerformance)

    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(trainData, trainLabel)
    guideToGraph['Gradient Boosting'] = clf.score(validationData, validationLabel)

def regression():

    maxRandomPerformance = []
    alphaValues = np.linspace(0,0.5,41)
    for value in alphaValues:
        clf = linear_model.Ridge(alpha = value)
        clf = clf.fit(trainData,trainLabel)
        score= clf.score(validationData, validationLabel)
        maxRandomPerformance.append(score)

    indexForMax = maxRandomPerformance.index(max(maxRandomPerformance))
    alphaTest = alphaValues[indexForMax]

    clfTest = linear_model.Ridge(alpha = alphaTest)
    clfTest.fit(trainData, trainLabel)
    scoreTest = clfTest.score(testData, testLabel)
    guideToGraph['Ridge Regression'] = scoreTest

    maxRandomPerformance = []
    cValues = [10**(-7),10**(-6),10**(-5),10**(-4),10**(-3),10**(-2),10**(-1),1]
    for value in cValues:
        clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=value)
        clf = clf.fit(trainData,trainLabel)
        score = clf.score(validationData, validationLabel)
        maxRandomPerformance.append(score)

    indexForMax = maxRandomPerformance.index(max(maxRandomPerformance))
    cTest = cValues[indexForMax]

    clfTest = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=cTest)
    clfTest.fit(trainData, trainLabel)
    scoreTest = clfTest.score(testData, testLabel)
    guideToGraph['Logistic Regression'] = scoreTest


def gaussianNBClassifier():
    clf = GaussianNB()
    clf.fit(trainData, trainLabel)
    guideToGraph['Gaussian Naive Bayes'] = clf.score(testData, testLabel)


def multinomialNBClassifier():
    maxRandomPerformance = []
    alphaValues = [0,10**(-7),10**(-6),10**(-5),10**(-4),10**(-3),10**(-2),10**(-1),1]
    for value in alphaValues:
        clf = MultinomialNB(alpha=value, fit_prior=True)
        clf = clf.fit(trainData,trainLabel)
        score = clf.score(validationData, validationLabel)
        maxRandomPerformance.append(score)

    indexForMax = maxRandomPerformance.index(max(maxRandomPerformance))
    alphaTest = alphaValues[indexForMax]

    clfTest = MultinomialNB(alpha=alphaTest, fit_prior=True)
    clfTest.fit(trainData, trainLabel)
    scoreTest = clfTest.score(testData, testLabel)
    guideToGraph['Multinomial Naive Bayes'] = scoreTest



def bernaulliNBClassifier():
    clf = BernoulliNB()
    clf.fit(trainData, trainLabel)
    guideToGraph['Bernaulli Naive Bayes'] = clf.score(validationData, validationLabel)


def polyNuSVC():
    maxRandomPerformance = []
    for deg in xrange(1,200):
        clf = NuSVC(kernel="poly",degree=deg)
        clf.fit(trainData, trainLabel)
        maxRandomPerformance.append(clf.score(validationData, validationLabel))
    guideToGraph['Polynomial Nu-SVC'] = max(maxRandomPerformance)

def linearNuSVC():
    clf = NuSVC(kernel="linear")
    clf.fit(trainData, trainLabel)
    guideToGraph['Linear Nu-SVC'] = clf.score(validationData, validationLabel)

def rbfNuSVC():
    maxRandomPerformance = []
    for gamma in xrange(1,200):
        clf = NuSVC(gamma=gamma)
        clf.fit(trainData, trainLabel)
        maxRandomPerformance.append(clf.score(validationData, validationLabel))
    guideToGraph['RBF Nu-SVC'] = max(maxRandomPerformance)


def sigmoidNuSVC():
    maxRandomPerformance = []
    for gamma in xrange(1,200):
        clf = NuSVC(kernel="sigmoid",gamma=gamma)
        clf.fit(trainData, trainLabel)
        maxRandomPerformance.append(clf.score(validationData, validationLabel))
    guideToGraph['Sigmoid Nu-SVC'] = max(maxRandomPerformance)

def linearSVCClass():
    maxRandomPerformance = []
    for value in xrange(10):
        clf = LinearSVC(penalty='l2', loss='hinge', dual=True, tol=0.0001, C=1.0, multi_class='crammer_singer', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)
        clf = clf.fit(trainData,trainLabel)
        maxRandomPerformance.append(clf.score(validationData, validationLabel))
    guideToGraph['Linear SVC'] = max(maxRandomPerformance)


knnClassifier()
radiusNeighborClassifier()
decisionTreeClassifier()
randomForestClassify()
regression()
gaussianNBClassifier()
multinomialNBClassifier()
bernaulliNBClassifier()
polyNuSVC()
linearNuSVC()
rbfNuSVC()
sigmoidNuSVC()

print ">Accuracies"
print guideToGraph
plotAccuracy(guideToGraph)
